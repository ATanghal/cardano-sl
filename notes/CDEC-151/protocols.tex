\documentclass{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath, amssymb, stmaryrd, latexsym, amsthm, mathtools}
\usepackage{mathpazo, times}
\usepackage{float}
\usepackage{listings}
\usepackage{url}
\usepackage{natbib}
% \usepackage{parskip} % very ugly with lemmas, invariants, etc without intervening text
\usepackage[disable]{todonotes}
\usepackage{slashed}
\usepackage{tikz}
\usepackage{forest}
\usepackage{IEEEtrantools}
\usepackage{microtype}
\usepackage{graphicx,color}

\usepackage{hyperref}
\hypersetup{
  colorlinks=false,
  linkcolor={blue},
  citecolor={blue},
  urlcolor={blue},
  linkbordercolor={white},
  citebordercolor={white},
  urlbordercolor={white}
}
\usepackage[capitalise,noabbrev,nameinlink]{cleveref}

% https://tex.stackexchange.com/questions/132823/ieeetrantools-clash-with-cleveref
\makeatletter
\let\if@IEEEissubequation\iffalse
\makeatother

\usetikzlibrary{arrows}

\newcommand{\njd}[1]{\textcolor{purple}{\emph{#1}}}
\newcommand{\avieth}[1]{\textcolor{blue}{\emph{#1}}}
\newcommand{\dcoutts}[1]{\textcolor{orange}{\emph{#1}}}
\addtolength{\marginparwidth}{-0.1\marginparwidth}

\newcommand{\powerset}[1]{\mathbb{P}(#1)}
\newcommand{\order}[1]{\mathcal{O}\left(#1\right)}
\newcommand{\restrictdom}{\lhd}
\newcommand{\subtractdom}{\mathbin{\slashed{\restrictdom}}}
\newcommand{\restrictrange}{\rhd}

\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator*{\argmin}{arg\,min} % thin space, limits underneath in displays
\DeclareMathOperator*{\minimum}{min}
\DeclareMathOperator*{\maximum}{max}

% Number within sections, and don't have separate counters for separate environments
\theoremstyle{definition}{
  \newtheorem{lemma}{Lemma}[section] % Number within sections
  \newtheorem{definition}[lemma]{Definition}
}
\theoremstyle{theorem}{
  \newtheorem{invariant}[lemma]{Invariant}
  \newtheorem{proofobligation}[lemma]{Proof Obligation}
}

\Crefname{invariant}{Invariant}{Invariants}

\numberwithin{equation}{lemma}

\floatstyle{boxed}
\restylefloat{figure}

\lstset{basicstyle=\ttfamily\small}

\raggedbottom

\begin{document}

\title{Design of IPC protocols for Cardano Shelly \\
       {\small (Version 0.2)} \\
       {\large \sc An IOHK technical report}}
\author{Duncan Coutts \\ {\small \texttt{duncan@well-typed.com}} \\
                         {\small \texttt{duncan.coutts@iohk.io}}
   \and Alex Vieth \\ {\small \texttt{alex@well-typed.com}}
   \and Neil Davies \\ {\small \texttt{neil.davies@pnsol.com}} \\
                       {\small \texttt{neil.davies@iohk.io}}
   }
\date{June 22, 2018}

\maketitle

\begin{abstract}
This document is intended as a discussion, leading to a design, of IPC
protocols for Cardano's Shelly release. The structure of the discussion is to
look at the requirements and ideas for application-level protocols, before
looking at how those can map onto lower level IPC protocols.
\end{abstract}

\tableofcontents

\section*{Version history}

\begin{description}
\item[Version 0.1, June 18, 2018] First draft based on previous notes and
                                  discussions with Alex.
\item[Version 0.2, June 22, 2018] Sketch of protocol proposal and goals for
                                  how to elaborate, based on further review
                                  and discussion with Alex and Neil.
\item[Version 0.3, July 4, 2018]  Comments from Neil.
\item[Version 0.4, July 8, 2018]  New section with alternative broadcast approach by Alex.
\item[Version 0.5, July 13, 2018] Extend the discussion of the alternative broadcast approach.
\end{description}

\section{Introduction}

\subsection{Scope}

In scope for this discussion is IPC that Cardano nodes engage in. We do want
to consider IPC between Cardano nodes and components such as wallets and
explorers, but not between wallets/explorers and other components.

Part of the discussion will be motivated by algorithms, data structures and
resource constraints within nodes, such has how nodes can represent their
blockchains, but this document is not primarily an analysis of those issues.

There are two relatively clearly distinct use cases for IPC for Cardano nodes:
\begin{itemize}
\item IPC between Cardano nodes that are engaged in the high level Ouroboros
      blockchain consensus protocol.
\item IPC between a Cardano node and a `chain consumer' component such as a
      wallet, explorer or other custom application.
\end{itemize}

It is plausible that both use cases could be served by the same protocol, but
this is not a given a priori.

\subsection{Goals}

First and foremost the protocols need to achieve their information exchange
requirements.

For the node-to-node protocol this is driven by the functional and performance
needs of Ouroboros. The node-to-node protocol is conducted in a P2P environment
with very limited trust between peers. The node-to-node protocol utilises
store-and-forward over selected \emph{bearers} which form the underlying
connectivity graph. A concern in this setting is asymmetric resource consumption
attacks. Ease of implementation is a nice to have, but is subordinate to the
other hard constraints.

A node-to-consumer protocol is intended to support blockchain applications
like wallets and explorers, or Cardano-specific caches or proxies. The setting
here is that a consumer trusts a node (a `chain producer') and just wants to
catch up and keep up with the blockchain of that producer. It is assumed that
a consumer only consumes from one producer (or one of a related set of
producers), so unlike in the node-to-node protocol there is no need to choose
between different available chains. The producer may still not fully trust the
consumer and does not want to be subject to highly asymmetric resource
consumption attacks. In this use case, because of the wider range of
applications that wish to consume the blockchain, having some options that are
easy to implement is more important, even if this involves a trade-off with
performance. That said, there are also use cases where tight integration is
possible and making the most efficient use of resources is more desirable.

\subsection{Why distinguish node-to-consumer}

It is worth discussing briefly why it makes sense to consider a node-to-consumer
protocol distinct from a node-to-node protocol.

There are a number of applications that simply want to consume the blockchain,
but are able to rely on an upstream trusted or semi-trusted Cardano consensus
node. These applications do not need to engage in the full consensus protocol,
and may be happy to delegate the necessary chain validation.

Examples include 3rd party applications that want to observe the blockchain,
examples being business processes triggered by transactions or analytics.  It
may also include certain kinds of light client that wish to follow the
blockchain but not do full validation.

Once one considers a node-to-consumer protocol as a first class citizen then it
opens up opportunities for different system architecture choices. The
architecture of the original Cardano Mainnet release was entirely homogeneous:
every node behaved the same, each trusted nothing but itself and paid the full
networking and processing cost of engaging in the consensus protocol.  In
particular everything was integrated into a single process: the consensus
algorithm itself, serving data to other peers and components such as the wallet
or explorer. If we were to have a robust and efficient node-to-consumer protocol
then we can make many other choices. \marginpar{\njd{Process memory space as
    the basis of trust}}.

With an efficient \emph{local} IPC protocol we can have applications like
wallets and explorers as separate processes. Even for tightly integrated
components it can make sense to run them in separate OS processes. Not only is
the timing constraints for a consensus node are much easier to manage when it
does not have to share CPU resources with chain consumers, but it enables the
use of operating system features to give finer control over resource consumption
for sophisticated end-users.
There have been cases in production where a highly
loaded wallet component takes more than its allowed allocation of CPU resources
and causes the local node to miss its deadlines.  By giving a consensus node a
dedicated CPU core it becomes more plausible to provide the necessary hard real
time guarantees. In addition, scaling on multi-core machines is significantly
easier with multiple OS processes than with a multi-threaded OS process with a
shared-heap. This could allow for larger capacity Cardano relay deployments
where there are multiple network facing proxy processes that all get their chain
from a single local consensus node.

With an efficient \emph{network} IPC protocol we can do similar things but
extend it across multiple machines. For example, clusters of relays operated
by a single organisation may be also to operate more efficiently using a
node-to-consumer protocol than a node-to-node protocol. Similarly it allows for
wallet or explorer-like applications that need to scale out, and are able to
make use of a trusted node.

\njd{In someways what is being proposed here is that by creating the notion of
  a `chain-observer' we can gain flexibility, reduce both computational and
  space complexity and enable a range of `lighter-weight' products and derived
  services.
  }

\subsection{Key references}

We will refer both to the original `Ouroboros classic' \citep{ouroboros-classic}
and to the later version `Ouroboros genesis' \citep{ouroboros-genesis}. We will
refer simply to `Ouroboros' where distinctions between the versions are
irrelevant.

\section{Node-to-consumer protocols}

TODO: cover notes on:
\begin{itemize}
\item chain producer representations and in-memory storage with high degrees of forking
  \begin{itemize}
  \item bounds on likely forking numbers, thus bounding the attack surface,
    likely to susceptible to analysis via some (pretty simple - i.e have
    analytical solutions) Markov Chain models.
    \item use-cases
  \end{itemize}
\item chain producer keeping state about consumers
\item immutable vs volatile distinction in representation and protocols
\item stateful protocol
\item stateless protocol
\item recursion as an indicator of completeness \marginpar{\njd{what does this mean Duncan?}}
\item family of protocol variations for different environments: STM, IO, local
  IPC, remote IPC
  \njd{\\noting different levels of implict trust here - we need
    to think whether the STM enviroment is one we treat differently (e.g. trust
    forwarding only correctly signed blocks reducing the checks in the consumer
    end) or do we assume even shared process nodes are potentially missbehaving
    and play up the way in which that helps defend against other forms of attack? }
\item optimised case for immutable chain, e.g. shared files
\item STM interface
\item coping with talking to a load-balanced cluster of imperfectly synced producers
\end{itemize}

\subsection{Goals}

\paragraph{Family of protocols}
We are interested in a family of chain following protocols to cover a range of
use cases. We are interested in:
\begin{itemize}
\item in-process protocols to be used for in-process chain consumers and as an
      aid to implementing the producer side of inter-process protocols.
      These will likely be exposed as APIs using STM or IO.
\item OS-local IPC protocols for out-of-process chain consumers
      such as wallets, and for implementing and scaling out the producer side
      of IPC network protocols.
\item efficient network IPC protocols for remote chain consumers, including
      wallets and network relays or proxies.
\item convenient stateless network IPC protocols for remote chain consumers
      where a trade-off towards the convenience of consumer implementation is
      appropriate.
\end{itemize}

In all these cases we will refer to the protocol peers as the chain producer
and the chain consumer or follower.

\paragraph{Resource use}
In the IPC cases we are interested in protocols where the chain producer can
ensure reasonable resource use even when the peer misbehaves to some degree. In
particular we do not want slow consumers to force excessive resource use by the
producer.

\paragraph{Recursion as an indicator of completeness} As mentioned, part of the
intention of having a family of related protocols is to be able to use some to
help implement others, but also to chain combinations together to allow
flexibility in application design. A measure of the completeness of each
protocol family member is that the consumer side should be enough to implement
the producer side of the same protocol or of another protocol in the family
(e.g. a consumer of an in-process protocol being able to implement producer
side of one of IPC protocols).

\subsection{Forking and resource bounds}

A chain producer following the Ouroboros protocol (or following another chain
producer) can of course switch forks and hence chain following protocols must
support this, and support it with reasonable resource bounds.

In Ouroboros Classic there is a helpful constraint that the maximum length an
alternative fork can diverge from a current chain is $K$ blocks. Ouroboros
Genesis does not include this constants but it appears that it could be
introduced without too much difficulty.

The benefit of this constraint is that it divides the blockchain into two parts:
a genuinely \emph{immutable} initial chain and a \emph{volatile} recent chain
fragment. An immutable chain allows implementation options with simple and
efficient on-disk storage. A volatile fragment that is bounded in length allows
implementation options using combinations of in-memory and on-disk data storage.
In particular, keeping track of up to $K$ blocks can easily be accommodated in
memory\footnote{The current implementation uses $K = 2160$.}.

\includegraphics[totalheight=2cm]{chain-diagram-imm-vol.pdf}

While the volatile chain fragment is only $K$ long, a chain following protocol
has to help chain consumers follow the volatile part of the chain as it
switches between forks and this may need to store more information.

Two general approaches to chain following protocols are as follows:
\begin{itemize}
\item The consumer and producer maintain enough information so that on a fork
      the producer and consumer are able to immediately and precisely determine
      how far the consumer has to roll back their chain before rolling forward
      on the new chain.
\item On a fork the consumer and producer have to engage in a protocol to
      determine where (roughly or precisely) the intersection between the
      consumer and producer's chains is and thus where the consumer needs to
      roll back to before rolling forward.
\end{itemize}

The first approach leads to more stateful protocols and the second approach to
stateless protocols. An appealing aspect of the first approach is being able to
go directly to the right place without needing any further steps.

A simple design following the first approach would be for the producer to keep
track of all forks it has gone through, at least within the last $K$ blocks.
This provides enough information for the producer to know the exact relationship
between old forks and the current chain, so that any consumer on any old fork
could be informed how to move to the new fork. The problem with this design is
that it could in the worst cases involve keeping track of a lot of forks, up to
$\mathbf{O}(K^2)$ of them. This is too many to hold in memory and so would lose
the simplicity of a design based on keeping information about recent blocks in
memory.

\subsection{Sketch of a stateful chain following IPC protocol}

In this stateful protocol there is a communication session with a bidirectional
unicast channel between the chain producer and follower. It is stateful in that
the chain producer maintains some state about the chain consumer.

The state that the producer maintains about the consumer is the consumer's
`read pointer', meaning the head of the consumer's chain and how that
corresponds to the producer's chain. In a typical state the consumer's read
pointer is on the producer's chain; the consumer simply asks for the next
change and in response is given the next block header; and the producer updates
the read pointer correspondingly. The protocol session is initiated with a few
steps necessary to establish the initial read pointer.

In general there 

\subsection{Sketch of a stateless chain following IPC protocol}



\section{Node-to-node protocol}

The Ouroboros consensus protocol \citep{ouroboros-classic} describes what it
needs from its network layer. Informally, that:
\begin{itemize}
\item nodes that create a new block in a time slot need to be able to broadcast
      their \emph{entire blockchain} to all other nodes, and;
\item within each time slot, all nodes to collect \emph{all the blockchains}
      they have received via broadcast and then to pick among them.
\end{itemize}

The challenge is to simulate this specification in bounded resources and to do
so without opening up opportunities for new attacks at the network level. Such
attacks might include preventing broadcast or local denial of service by making
nodes consume excess resources (time, memory, network, CPU).

There are a few aspects to bounding resource use in this setting.
\begin{enumerate}
\item We can try to establish some absolute bound on the required resources.
\item With or without an absolute bound we can try to arrange things so that it
      is difficult for an adversarial party to create a lot of work for honest
      parties.
\item If we cannot establish absolute resource bounds for a perfect simulation,
      or the bounds might be too large for some instances, we can consider what
      choices an instance with limited resources should make to achieve a good
      enough simulation.
\end{enumerate}

Obviously na\"ively broadcasting entire chains is not something that can be
done with bounded resources since there is no bound to the chain length.
Obviously the intention is to communicate new blocks and to share and reuse the
parts of the chain that have not changed, though this is easier said than done.

There is however another dimension to the resource bounding problem. In a
proof-of-work blockchain protocol it is expensive for adversarial parties to
create lots of `fake' blocks, so there is in practice a limit on the number of
such blocks that honest parties need to consider. In proof-of-stake blockchain
protocols there is no such constraint: adversarial parties can create many
signed blocks.

\subsection{Drawbacks in the current Ouroboros network protocol implementation}

In the current architectural deployment there is an assumption that certain
nodes are being run by trusted parties and, as such, non-adversarial. There is
no current formal argument as to how, in the presence of nodes acting
adversarially with respect to data diffusion, at what level of adversarial
action performance is compromised.

It is unclear if or how the chain broadcast logic corresponds to the chain
broadcast specified in the Ouroboros paper. Rather than implementing broadcast
directly, it interleaves chain adoption with relaying of block headers. This
may not be wrong, but there is no stated argument for it being faithful.

The chain broadcast logic is vulnerable to straightforward resource consumption
attacks: it responds to receiving a new chain head header by trying to chase
that down before doing anything else. If this is slow (and attackers can make
it slow) the logic does not proceed with considering headers from any other
peer.

The broadcast and chain logic are intertwined in ways that are complex and
increase latency for relaying blocks, which limits the diameter of the network
that can be supported for a given slot length.

\subsection{The major challenge}

The major challenge in the design of a practical IPC protocol for Ouroboros is
to find something that satisfies what Ouroboros specifies but does so in a way
that is not open to various kinds of attacks from adversarial nodes.

Ouroboros specifies the overall state changes involved in agents obtaining
and selecting candidate chains. The specification describes the state changes
in a modular way, composed of two phases: broadcast of chains followed by
selecting amongst all the candidate chains received.

As mentioned previously, broadcasting whole chains is not practical, but it is
relatively straightforward to recast this in in terms of broadcasting (or
relaying) blocks.

The more subtle problem is that while the specification describes chain
broadcast and selection as separate phases, we cannot implement them separately.
We must implement \emph{broadcast in the context of chain selection}, meaning
that we must take advantage of the constraints imposed by chain selection to
limit what can be broadcast. If we provided broadcast directly without any
constraints then it could easily be abused by adversaries to conduct highly
asymmetric resource consumption attacks.

So we want a design that achieves the equivalent effect of chain broadcast
followed by local chain selection, but it is acceptable to intermingle the
chain selection logic with the broadcast logic, indeed it would appear to be
necessary to achieve a design that works in bounded resources.

\subsection{Interleaving chain selection with relaying}

With the previous point in mind, it is tempting to consider pursuing an
approach where each node subscribes to and follows the chains of a number of
its peers and continuously selects between those chains following the Ouroboros
chain selection rule. The intuition is that that this should make it easier
bound a node's resource use since it only need consider the N potential chains
from its N immediate peers.

The challenge in this interleaving approach is that the argument that it is
equivalent to what Ouroboros specifies is not trivial. By contrast the
equivalence argument is much clearer if we broadcast the block header of each
chain's head and then chase down the rest of the chain back to an intersection
point.

\subsection{Basic techniques to help bound resource use}

There are a number of tricks to help bound resource use that are standard for
blockchain communication. We can break up the blockchain into individual blocks,
and blocks themselves into a small fixed size header and a larger variable
sized body. The basic idea is that we initiate a chain broadcast by
communicating the block header for the head block in the chain.

In PoW blockchain algorithms the header can contain the representation of a
proof of work, while in PoS the header contains representation of the proof of
stake: a signature showing that it was created by the appropriate party. In
Ouroboros the PoS signature means that nodes that are up to date (at least
within the same epoch) can verify that the header itself is plausible, and
exclude incorrectly signed or implausible headers.

A small fixed size header means that we can bound the network resource use
to send or receive a single header, and can also bound the CPU resources needed
to verify the header.

\subsection{Review of constraints on chain broadcast}

The Ouroboros algorithm imposes a number of useful constraints on chain
broadcast.

\begin{itemize}
\item Ouroboros specifies that chains with blocks from slots in the future are
      invalid. The signed block header contains the slot number so we can
      exclude such chains just by looking at the block header of the head block
      in the chain (which is the one we broadcast).
      \avieth{If a slot leader can mint a new block and deliver the header to
      a peer within the clock skew of that peer then it may be incorrectly
      rejected. We may want to set some tolerance threshold.}
\item Ouroboros specifies that when a node adopts a new chain it only ever
      picks one strictly longer than its current one. The signed block header
      contains the block number so by comparing the block number of the
      broadcast header against the current length of the node's chain, we can
      exclude chains that are shorter and so could never be picked.
      \avieth{Further, it is never necessary for a node to relay a chain when it
      knows of a better one. This may be very useful in practice: at most one
      chain must be tracked per peer. An adversary cannot make an honest node
      retain multiple chains of its own broadcast.}
\item Ouroboros Classic (but not Genesis) specifies that a node will only ever pick
      a chain that diverges from its current chain within the last K blocks,
      implying that forks can be at most K long. This places a bound (of K) on
      the range in which a node needs to look for an intersection between the
      new purported chain (represented by the header of its head block) and its
      own current chain. This bounds the number of block headers that a node
      would ever need to download to obtain all headers for the candidate chain.
\item Each block must be signed by the appropriate slot leader. This signature
      -- which is the proof of stake -- can be checked by any node that has
      the chain up to the current epoch.
\item In Ouroboros Classic, there is only ever one legitimate leader for each
      time slot, and non-adversarial players never sign more than one block
      for the slots in which they are the leader.
\item In Ouroboros Genesis, the situation is similar: there can be more than one
      legitimate leader for a time slot but the number of leaders in a slot
      follows a distribution that makes a large number highly unlikely (and
      this is not controlled by adversarial players). Again, non-adversarial
      players never sign more than one block for the slots in which they are
      the leader.
\item In both Ouroboros Classic and Genesis it is possible for adversarial
      players to sign multiple blocks for the same slot.
\item \avieth{Theorem 4.13 from the original Ouroboros paper describes the
      probability of the existence of a flat fork of length $n$: 2 tines of
      equal block count intersecting $n$ slots prior. This is applicable to
      what we're doing here, both for resource bounds and for correctness.}
\end{itemize}

\subsection{Discussion of bounds}
\dcoutts{This section needs to be revised in the light of the interleaving
approach.}

The combination of these constraints does place a limit on the number and
length of plausibly valid chains that an adversary can create and try to get
honest parties to chase. Given that some honest parties may have gone offline
and be a long way behind the chain, and in particular will not be able to
validate signatures in block headers. So it is worth splitting the analysis
into the case of nodes that are within the current epoch, and a case for nodes
that are further behind. We start with the first case.

In particular, plausibly valid chains would have to start with a valid header
that falls into a slot after the last block of the target victim's chain
but only up to the current time slot. Plausibly valid chains can only extend
back up to K blocks (max 2K slots). The victim is able to assume that other
honest nodes do not sign more than one block per slot, this imposes the
constraint that the adversary can only send one header per slot within the
range just described.
\avieth{Why? I don't see it. Plausibly valid chains can extend more than
  K blocks, no? Maybe the language is unclear.}

It is worth noting that just because honest nodes do not sign more than one
block per slot, it does not mean that different honest nodes will not have
different blocks in the same slot, since an adversary can in previous slots
have sent different headers to different nodes.

\njd{\centering I'm not certain I agree with this, or perhaps I don't agree
  with the implied generality. Honest generator nodes will only generate one
  block per slot - so only one of those can exist per slot. Dishonest nodes can
  generate many such blocks, agreed - maybe that needs to be brought out.}

\avieth{What's the disagreement here?}

\paragraph{An overall bound} Suppose the victim node has a chain with
at least $K$ blocks covering the last $K \leq s \leq 2K$ slots, and $n$ slots
between the slot of the head block of chain on the victim node's and the
current time slot. Suppose also that the adversary controls a fraction
$0 \leq \rho < 1/2$ of the stake in the current epoch.

In that case the adversary can create approximately $n * \rho$ chains (the
specific slots in which the adversary is leader is drawn from a probability
distribution). In the worst case this approaches $n / 2$, but of course the
adversary is allowed to wait until it gets lucky in the probability
distribution. Each of these chains can be up to approximately $(n+K) * \rho$
long. Of course only the chains that are actually longer than the victim node's
current chain are valid.

\njd{This would seem to be the right spot for the simple MC analysis on
  distribution of burst lengths\\
\includegraphics[totalheight=2cm]{burst-length-mc.png}}

\subsection{Plausible design approaches}

As discussed above we must design chain broadcast in the context of chain
selection. There are at least two plausible design approaches that we have
considered.

The first involves relaying the block header of the chain head followed by
chasing other block headers and bodies. It involves taking advantage of the
chain validity and selection rules to apply validation as early as possible,
including checking the signatures on block headers. It does not however involve
intermediate nodes adopting a chain prior to relaying.

The second does involve intermediate nodes adopting a chain prior to relaying.
Each node keeps track of the chains of its immediate neighbours in the network,
which is equivalent to nodes relaying their chains once they have adopted an
updated chain. So a new chain can propagate from node to node but at each
hop it is only relayed if the node selects the new chain itself.

An advantage of the first approach is that it is easier to argue that it is
equivalent to what Ouroboros specifies. By relaying block headers in advance
of requesting blocks and doing full chain validation it is possible to minimise
the hop-by-hop latency.

An advantage of the second approach is that by doing more validation in advance
of relaying, the number of initially plausible but ultimately invalid chains
that each node must consider can be curtailed considerably. The second approach
would appear to involve less implementation complexity by avoiding having to
track the state of multiple outstanding requests for more block headers and
bodies and may be able to reuse much of the implementation of a node-to-consumer
chain following protocol. A disadvantage is that the simplest approach to
adopting a chain before forwarding would involve a high hop-by-hop latency
since a block header could not be sent on before a block body was received.
More complex variants may be able to overcome this limitation. And of course
the whole approach is only legitimate if we can convincingly argue that it is
equivalent to what Ouroboros specifies.

\subsection{An argument for interleaving chain selection with relaying}

This is an attempt to construct an informal argument that designs based on
interleaving chain relaying with chain selection may be equivalent to chain
broadcast followed by chain selection.

Let us start with the basic model: chain broadcast followed by chain selection.
In this model all nodes are able to send on a broadcast channel and all nodes
can reliably receive chains on this channel. The slot leader adds a new block
to its chain and sends it on the broadcast channel to all nodes. In each time
slot, all nodes collect all chains received on the broadcast channel into a set.
At the end of the time slot each node selects their best chain, given their
existing chain and the set of candidate chains received via broadcast. The
chain selection function selects the longest valid chain that is longer than
the current chain. Ties are broken arbitrarily.

An argument that some other proposed model is equivalent to this basic model
has to argue that the chain that is selected by each honest node is the same
as in the basic model. In this context `the same chain' can involve refinements
of the arbitrary choice between chains of the same length. More precisely we
could recast the chain selection function to return the set of all alternatives
which we are indifferent between. In this style we can say that a model is a
refinement if the set of selected alternative chains is a non-empty subset of
the set from the original model.

Let us now consider a model that is one step in the intended direction but
still relatively simple. Instead of a broadcast channel, assume that the
nodes are arranged in a graph with unicast channels on the graph edges. We
assume that all honest nodes are at least connected to each other via other
honest nodes\footnote{This is an assumption that any refinement to a P2P
network needs to make, and an assumption that the P2P connectivity layer must
discharge.}. The slot leader adds a new block to its chain and sends it on the
unicast channels to all its immediate neighbour nodes. Upon receiving a chain
on a channel from a neighbour, a node validates the chain and does chain
selection between the new candidate chain and its current chain. If it selects
the new chain then it relays the new chain on the unicast channels to all its
immediate neighbour nodes.

This model involves switching from chain selection as an operation on a set of
candidate chains and the current chain, to being a binary operation between a
single candidate chain and the current chain. We claim as a lemma that
compositions of the binary operator version is equivalent to the whole-set
version, modulo differences between indifferent alternatives.

\begin{align*}
\mathsf{selectChain} & \in \mathsf{Chain} \to \mathbb{P}~\mathsf{Chain}
                                          \to \mathbb{P}~\mathsf{Chain} \\
\mathsf{selectChain} ~ c ~ cs & = blah
\end{align*}

\avieth{\subsection{Proposal for a data structure for forks over $k$ slots.}}

\avieth{For each peer to which the node is connected, at most one chain (their
  claimed best chain) is retained. An honest node only broadcasts or relays
  a tip-of-chain if it has judged it to be the best chain it knows. There is
  no reason to broadcast or relay any other chain: by broadcasting or relaying
  the better chain, the honest receiving party will always prefer it to the
  weaker one, so broadcasting or relaying the weaker one would be wasteful.}

\avieth{When a tip-of-chain announcment is received from a peer, and it's valid
  (signed by the appropriate slot leader) and better (higher block count) than
  the peer's previously announced best tip-of-chain (if any), the receiver
  either:\\}

  \begin{itemize}
    \item \avieth{If the parent of the header is known, and it is also the tip of the
          local node's best chain, then the new header can be relayed
          immediately. The peer will send the body as well which can also be
          relayed immediately upon reception.}
    \item \avieth{If the parent of the header is not known, some protocol to find
          the intersection is engaged. It could be a naive request for headers
          of ancestors, or something more complicated such as the one described
          in the ``A protocol proposal" section of this document. In any case,
          eventually either the intersection is found and the complete peer's
          chain downloaded (up to at most $k$ blocks), or the peer fails to
          provide enough information and the chain is eventually discarded.}
  \end{itemize}

  \avieth{A loose upper bound on space use is the number of peers multiplied by $k$.
  As for network I/O and CPU resource use: an adversary can only induce an
  honest node to work on one chain, namely the adversary's claimed best chain.
  By judiciously queueing network input we can ensure that adversaries cannot
  cut out honests.}

  \avieth{The probabilty that a node has multiple chains which disagree on the
  slot $n$ behind the current slot is marginal for sufficiently large $n$
  (theorem 4.13). This gives a local correctness property: by increasing the
  number of slots retained by this forking data struture ($k$) we can
  decrease the probability that the oldest slot will include more than one
  candidate (mutiple blocks, or no block, because some maximal chain is known
  with no block at this slot). Multiple candidates for the oldest slot means
  there is a flat fork of size $k$: 2 tines of equal block count intersecting
  at the slot $k$ behind the current slot. This is highly unlikely for high
  $k$ (negative exponential in $k$).}

  \avieth{As for consistency between peers: if 2 nodes disagree on the slot $k$ behind
  the current slot, it's not necessarily a flat fork: one of the chains could
  have a lower block count than the other, which means the disagreement is due
  to communication failure. In particular, the peer with the better chain
  failed to broadcast its chain to the peer with the weaker chain. In order to
  get some guarantee on inter-node consistency, we might use properties of
  the network, perhaps some $\Delta Q$ analysis.}

  \avieth{Call the better tine $T_b$ and the worse $T_w$. $T_b$ has a higher
  block count $bc(T_b)$ than $T_w$, so there is some subchain of $T_b$ which is
  a flat fork of $T_w$, obtained by removing the $bc(T_b) - bc(T_w)$ newest
  blocks from $T_b$. The size of this flat fork is probably very small
  (theorem 4.13). If the disagreement is for a block $k$ behind the current
  slot then, since this flat fork is probably small, the difference
  $bc(T_b) - bc(T_w)$ must be comparatively large, and so the node with the
  better chain must have had a comparatively high number of slots in which
  it could have informed the node with the weaker chain of its better chain.
  This is informal but I think it captures the idea and we may be able to
  work it into some explict probabilistic guarantee.}

\avieth{\subsection{Broadcasting the best chain}}

  \avieth{Take some associative, commutative, idempotent function
    $merge :: Chain \rightarrow Chain \rightarrow Chain$.
    Ouroboros chain selection is suitable,
    modulo chains of equal length equivalence relation.}

  \avieth{Any expression of $merge$s is equivalent to the set of unique $Chain$s
    which appear in it: order doesn't matter, association doesn't matter, and
    duplicates are irrelevant.}

  \avieth{In ideal broadcast, every node learns of every other node's $Chain$
    and computes the $merge$ of all of these with its $Chain$. This is
    identified by the set of unique $Chain$s (modulo equal length) over all
    nodes.}

  \avieth{In broadcast via store-and-forward of the $merge$ of the forwarded
    thing with the local state, every node learns of every other node's state
    via one or more paths, over which it is $merge$d with the states of other
    nodes (the forwarding nodes). These $merge$ expressions are then $merge$d
    by the terminal node to give another $merge$ expression, which is, just as
    for ideal broadcast, identified by the set of unique $Chain$s over all
    nodes, and so it agrees with ideal broadcast.}

  \avieth{If a forwarding node finds that the $merge$ of the $Chain$ to forward
    with its own $Chain$ is equal to its own $Chain$, it can safely not forward
    anything, because the receiving nodes are already aware of the better
    $Chain$ (this node already forwarded it). Commutativity and associativity
    means that, for any $merge$ expression involving both of these chains, the
    weaker can always be eliminated.\\}


\subsubsection{Raising the difficulty for attackers}

As designers of the protocol game we want to structure it such that the
defending party can make best use of the available bounds so that the attacking
party cannot do much better than those bounds. In this case that means trying
to avoid consuming too much network or other resources downloading chains that
we will later discover are invalid. Attacking nodes can lie, and we must
structure the game so that we can catch them out on the lie within bounded and
reasonable resources.

There are a few observations we can make from the above bounds. Firstly,
nodes that are further behind are much more vulnerable since there are many
more starting points for potential chains that an attacker can use.

An important observation is that attackers with a lower stake proportion $\rho$
can initially claim that they have a candidate chain that is longer than the
victim's chain and that intersects with it many blocks back, but they will not
be able to substantiate that claim. That is because the attacker can only make
signed block headers for the slots it controls. They can use slots they control
within the $n$ slots between the victim's chain head and the current time slot,
but the further back the attacker tries to make the intersection, they soon
run into the problem that the density of chain they can create is much lower
than the density of the victim's chain. So while the attacker has an $n * \rho$
head start, they soon loose out in trying to construct a valid chain.

Given that the attacker can lie, we wish to structure the game so that we can
catch them out on the lie with a minimum use of resources by the victim. We can
use techniques such as requiring the attacker to reveal more information up
front making it easier for the victim to detect the lie later, and we can use
tricks like making certain challenges randomly so that the attacker cannot pick
a perfect strategy up front.

\subsubsection{Judicious choices on resource use}

If the resource bounds are in the worst case still more than the available
resources of the instance of the implementation, we may still be able to
make adequate progress. If so, it involves deciding carefully which options
to pursue and which to pass up. This requires careful analysis 

\subsection{A protocol proposal}

In this section we will propose a protocol at a high level with a general
description of the algorithm that the defending party can follow.

We need to analyse this protocol in at least the following cases
\begin{itemize}
\item A high stake adversary: one that can construct multiple long enough valid
chains according to the bounds, and many other plausible long but ultimately
invalid chains.
\item A low stake adversary: there are many more low stake adversaries than
high stake ones, so this is an important case. We need to be sure we can deal
with multiple low stake adversaries quickly.
\item A low or zero stake adversaries that rely not on signing their own blocks
but on grabbing real valid signed blocks and trying to cause mischief with
them. For example, the algorithm should deal efficiently with an attacker that
simply re-broadcasts many valid headers from the current chain.
\item The protocol game we create is reversible: whatever protocol we define
we must consider in both directions, either side can be the honest node with
the other the adversary. We must analyse the resource use from the broadcast
side as well as the receiving side.
\end{itemize}

The sketch of the protocol is as follows:
\begin{enumerate}
\item The (potential) adversary sends a new block header messages.
      The block header message contains a signed block header (roughly ~600
      bytes) and a list of pairs of slot number and hash of a predefined
      set of preceding blocks on their chain. We could use e.g. 16 immediately
      preceding and then ${2^n | n \in {5..15}}$ blocks earlier. This is an
      initial declaration by the attacker and can be used to find the lower
      bound on the purported chain intersection point. The purpose of providing
      the first few densely is to deal efficiently with the common and
      non-adversarial cases of follow-on blocks or short forks.
\item The defender must check the block signature and discard it if it is
      invalid. Honest nodes should never forward invalid signed blocks so this
      indicates the immediate peer\marginpar{\njd{the direct bearer peer}} is dishonest and should be dropped.
\item Assuming the block signature is valid, and it's slot number and block
      number indicate it is of interest, the node must now remember the slot
      and hash of this block header since any other validly signed block header
      in this slot indicates both broadcasts were adversarial and can be
      ignored. The node can also now re-broadcast this header to its other
      peers that are subscribed.
\item The defender, by looking at the purported points on the new chain can now
      determine a lower bound on where the chain intersection would be (or that
      there is none and it can be discarded). This is true because the points
      on the chain cover up to one epoch back.
\item The defender now issues a request containing a set of block numbers (or
      offsets backwards from the chain head) on the attackers chain. The
      request is for the corresponding slot numbers and block header hashes.
      These can be made quite small, e.g. the first 64bits of the block hashes\marginpar{\njd{they could be even smaller? what risk in 8, 16 or 32 bits?}}.
      The purpose of this request is to force the attacker to reveal
      information up front so that it cannot take an adaptive approach to our
      later requests. If the range that the defender is interested in is too
      big for a single request, it should pick points (or ranges of points?)
      randomly. \\ \njd{If smaller hashes are not that much weaker this might help with message sizes at this point}
\item The attacker now sends the slot numbers and block header hashes, or the
      request times out, and the defender can stop chasing this chain. Note
      that this does not indicate the immediate peer is an adversary since we
      re-broadcast headers prior to validating the whole chain of headers.
\item The defender can now ask for a selection of block headers, based on the
      block numbers they asked for previously. Block headers are a bit larger
      so we can only ask for fewer than in the previous request. The defender
      should ask for points on the chain randomly. This is to prevent the
      attacker from using the slots they do control in a strategic way.
\item The attacker must supply the headers requested (or abandon).
\item The defender can now validate these headers and check them against the
      slot numbers and hash prefixes previously declared by the attacker. The
      argument is that if the attacker in fact can only sign a proportion of
      the slots they are claiming (or cannot make the links or block numbers
      match up), then by repeatedly sampling them randomly the defender has
      a very high chance of catching them out in the lie, without having to
      download the whole purported chain. The smaller the adversarial stake
      $\rho$ and the longer the claimed fork the greater the chance of catching
      the lie quickly.
\item The defender can iterate asking for more block headers (and if it was
      necessary more slot numbers and block header hashes) until either an
      invalid header chain is discovered or all the headers from the
      intersection point to the chain head are found. It may be appropriate
      (if the analysis allows) to use larger batches for subsequent requests
      as the probability of a lie dwindles.
\item Once the defender has established a full chain of headers, it can request
      the block bodies, either from the same node or from any other peer.
\item Finally it can apply the new chain to its chain state if it is still
      longer than its current chain.
\item It is important to abandon this protocol if it takes too long overall.
      A single slot-worth of time may be appropriate. \\ \njd{maybe this should be a progress condition not an abandonment. What would the mitigation action be if abandoned? - restarting could bery well be exactly the wrong thing to do - i.e can we structure the protocol interactions so assure monotonic progress}
\item It is important to retain valid signed headers in a cache, even if the
      chain chasing was abandoned due to a timeout. This is because while an
      attacker can make lots of different invalid chains that are all wildly
      divergent, the honest chain gets built upon, so if we are in a situation
      where we are trying to chase many possible chains, while we may not be
      able to complete the chasing of the honest chain within the timeout we
      can hopefully make progress on it at better than real time, and so b
      remembering it from slot to slot we can build on it and eventually chase
      down the whole chain of headers. It is not necessary to retain headers
      when the chain was discovered to be invalid.
\end{enumerate}

TODO: need better name than attacker here, since the immediate peer may be
honest and just be proxying for the real attacker. This is due to us wanting
to broadcast headers before waiting for the full chain to be validated.\\
\njd{fuzzy logic here we come? or some Bayesian reasoning approach?}
\avieth{How's this: only relay the header immediately if its parent chain is
  already known and valid? Then we get a speedup for the typical case: relaying
  a block freshly minted by an honest slot leader. In other cases, it won't be
  relayed until it has been downloaded and verified.}

TODO: during this whole process, the chain state may have updated already and
the chain we're chasing may be redundant.

TODO: consider priority between the chains we're chasing, e.g. when we get a
full chain of headers, dedicate the bandwidth to fetching the blocks rather
than chasing more? Do it adaptively as the lie probability dwindles? Or does
that dangerously favour short adversary chains over genuine longer ones? \\

\njd{If we tie key resource consumption ratio - thinking mainly
  network resource here - to fractional belief and we only manipulate
  ratios not preemption (i.e weight not pitch) then a short-chain
  attacker who dawdled would free up resources for a longer one to
  overtake it. We may be able to make this a non-problem.}

\bibliographystyle{apalike}
\bibliography{references}

\appendix
\section{Credible worst case scenario(s)}
\subsection{Bounding case}
\begin{itemize}
\item attacker can totally eclipse node
\item attacker has  $\rho = \frac{1}{2} - \epsilon, \epsilon > 0$ stake
\end{itemize}
\subsection{Duration of miss-information}
\begin{itemize}
\item how many slots could an attacker maintain a fiction with a)
  unfettered power of eclipse; b) $\rho$ adverserial stake at its disposal.
\item what indicators of certainty are available to inform end user?
\end{itemize}
\subsection{Inherent Assymetry}
\begin{itemize}
\item How much un-eclipsed information is needed to detect eclipse? Is
  a unicast channel enough? (this would permit other technological
  approaches in the longer run)
\item Given that a node is not totally eclipsed (i.e $\exists$
  potentially reachable non-adversrial bearer node) how does this help?
\end{itemize}  


\end{document}
